# 官方deepseek

## python测试
```
from openai import OpenAI

client = OpenAI(api_key="sk-4d8a1dffc0284d039d20af1f6f9ad29a", base_url="https://api.deepseek.com")

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=[
        {"role": "system", "content": "You are a helpful assistant"},
        {"role": "user", "content": "Hello"},
    ],
    stream=False
)

print(response.choices[0].message.content)
```

## nextchat docker run
docker run -d --name chatgpt-next-web \
    -p 10130:3000 \
    --restart=always \
    -e OPENAI_API_KEY=sk-4d8a1dffc0284d039d20af1f6f9ad29a \
    -e BASE_URL=https://api.deepseek.com \
    -e CUSTOM_MODELS=deepseek-chat \
    -e DEFAULT_MODEL=deepseek-chat \
    -e CODE=dream13889 \
    yidadaa/chatgpt-next-web

## next docker_compose.yml

services:
  chatgpt-next-web:
    image: yidadaa/chatgpt-next-web
    container_name: chatgpt-next-web
    ports:
      - "10190:3000"
    environment:
      - OPENAI_API_KEY=sk-4d8a1dffc0284d039d20af1f6f9ad29a
      - CODE=joshzhong
      - BASE_URL=https://api.deepseek.com
      - CUSTOM_MODELS=deepseek-chat
      - DEFAULT_MODEL=deepseek-chat
    restart: unless-stopped



# 硅基流动
# 参考文档链接：https://docs.siliconflow.cn/usercases/use-siliconcloud-in-nextchat


##  python测试
```
import requests

url = "https://api.siliconflow.cn/v1/chat/completions"

payload = {
    "model": "deepseek-ai/DeepSeek-V3",
    "messages": [
        {
            "role": "user",
            "content": "中国大模型行业2025年将会迎来哪些机遇和挑战？"
        }
    ],
    "stream": False,
    "max_tokens": 512,
    "stop": ["null"],
    "temperature": 0.7,
    "top_p": 0.7,
    "top_k": 50,
    "frequency_penalty": 0.5,
    "n": 1,
    "response_format": {"type": "text"},
    "tools": [
        {
            "type": "function",
            "function": {
                "description": "<string>",
                "name": "<string>",
                "parameters": {},
                "strict": False
            }
        }
    ]
}
headers = {
    "Authorization": "Bearer sk-gerpfoatosegxwbmgiqlhrpqrvftxoygfjuhuznzsavqjcqy",
    "Content-Type": "application/json"
}

response = requests.request("POST", url, json=payload, headers=headers)

print(response.text)
```

## nextchat使用硅基流动
docker run -d --name chatgpt-next-web11 \
    -p 10199:3000 \
    --restart=always \
    -e OPENAI_API_KEY=sk-gerpfoatosegxwbmgiqlhrpqrvftxoygfjuhuznzsavqjcqy \
    -e BASE_URL=https://api.siliconflow.cn \
    -e CUSTOM_MODELS=deepseek-ai/DeepSeek-V3 \
    -e DEFAULT_MODEL=deepseek-ai/DeepSeek-V3 \
    -e CODE=sunline \
    yidadaa/chatgpt-next-web


# 逆向api（deepseek-free-api）
# 浏览器访问官方对话来获取token
{"value":"8OZJC+ow2IRpK9JIgTGZ5ygANfgzBnefL3mx0VIYJqqQtvGeQQszqTHXBRwXrCfB","__version":"0"}

## deepseek-free-api 的 docker-compose.yml
version: '3'

services:
  deepseek-free-api:
    container_name: deepseek-free-api
    image: vinlic/deepseek-free-api:latest
    restart: unless-stopped
    ports:
      - "8127:8000"
    environment:
      - TZ=Asia/Shanghai



## 测试是否可用
```
import requests
import json


url = "http://10.22.51.64:8127/v1/chat/completions"

# Authorization Token
token = "8OZJC+ow2IRpK9JIgTGZ5ygANfgzBnefL3mx0VIYJqqQtvGeQQszqTHXBRwXrCfB"


headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {token}"
}

data = {
    "model": "deepseek",
    "messages": [
        {
            "role": "user",
            "content": "你是deepseek v3模型吗？"
        }
    ],
    "stream": False
}

response = requests.post(url, headers=headers, data=json.dumps(data))


if response.status_code == 200:
    print("响应成功:")
    print(response.json())  # 打印返回的 JSON 数据
else:
    print(f"请求失败，状态码: {response.status_code}")
    print(response.text)  # 打印错误信息
```

## nextchat部署deepseek-free-api

docker run -d --name chatgpt-next-web3 \
 -p 3004:3000 \
 --restart=always \
 -e OPENAI_API_KEY=sk-kL4CJZTdq5efBUN24f0bFaAb09D04512B1705a72B9D8FcA1 \
 -e BASE_URL=http://172.18.0.104:3000/ \
 -e CUSTOM_MODELS=-all,deepseek-free-api \
 -e CODE=123456789 \
 yidadaa/chatgpt-next-web


## oneapi使用nextchat
docker run -d --name chatgpt-next-web3 \
 -p 3004:3000 \
 --restart=always \
 -e OPENAI_API_KEY=sk-kL4CJZTdq5efBUN24f0bFaAb09D04512B1705a72B9D8FcA1 \
 -e BASE_URL=http://172.18.0.104:3000/ \
 -e CUSTOM_MODELS=-all,deepseek-r1:14b \
 -e CODE=123456789 \
 yidadaa/chatgpt-next-web



 # ollama 自带的 api
docker run -d --name chatgpt-next-web \
  -p 10130:3000 \
  --restart=always \
  -e OPENAI_API_KEY=ollama-dummy-key \
  -e BASE_URL=http://192.168.1.8:8000 \
  -e CUSTOM_MODELS="-all,deepseek-r1:14b" \
  yidadaa/chatgpt-next-web